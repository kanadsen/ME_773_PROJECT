{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING REQUIRED PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages_imp import*\n",
    "np.random.seed(34)\n",
    "\n",
    "#Importing functions from jupyter notebook\n",
    "from ipynb.fs.full.dat_preprocess import*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling gpu based torch model\n",
    "import torch\n",
    "torch.manual_seed(1) # No of instances\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECLARE THE VARIABLES TO BE USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns=[]  # Stores the list of columns to be dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD THE FINAL DATASET AFTER EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014301061630249023,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Executing",
       "rate": null,
       "total": 20,
       "unit": "cell",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff4add20be5437998955f2257daf999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/20 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20631 entries, 0 to 20630\n",
      "Data columns (total 28 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ENGINE_ID        20631 non-null  int64  \n",
      " 1   CONDITION_ID     20631 non-null  int64  \n",
      " 2   Cycle_Time       20631 non-null  int64  \n",
      " 3   OpSet1           20631 non-null  float64\n",
      " 4   OpSet2           20631 non-null  float64\n",
      " 5   OpSet3           20631 non-null  float64\n",
      " 6   SensorMeasure1   20631 non-null  float64\n",
      " 7   SensorMeasure2   20631 non-null  float64\n",
      " 8   SensorMeasure3   20631 non-null  float64\n",
      " 9   SensorMeasure4   20631 non-null  float64\n",
      " 10  SensorMeasure5   20631 non-null  float64\n",
      " 11  SensorMeasure6   20631 non-null  float64\n",
      " 12  SensorMeasure7   20631 non-null  float64\n",
      " 13  SensorMeasure8   20631 non-null  float64\n",
      " 14  SensorMeasure9   20631 non-null  float64\n",
      " 15  SensorMeasure10  20631 non-null  float64\n",
      " 16  SensorMeasure11  20631 non-null  float64\n",
      " 17  SensorMeasure12  20631 non-null  float64\n",
      " 18  SensorMeasure13  20631 non-null  float64\n",
      " 19  SensorMeasure14  20631 non-null  float64\n",
      " 20  SensorMeasure15  20631 non-null  float64\n",
      " 21  SensorMeasure16  20631 non-null  float64\n",
      " 22  SensorMeasure17  20631 non-null  int64  \n",
      " 23  SensorMeasure18  20631 non-null  int64  \n",
      " 24  SensorMeasure19  20631 non-null  float64\n",
      " 25  SensorMeasure20  20631 non-null  float64\n",
      " 26  SensorMeasure21  20631 non-null  float64\n",
      " 27  RUL              20631 non-null  int64  \n",
      "dtypes: float64(22), int64(6)\n",
      "memory usage: 4.4 MB\n",
      "Columns without data: \n",
      "[]\n",
      "\n",
      "Columns with constant values: \n",
      "['CONDITION_ID', 'OpSet3', 'SensorMeasure1', 'SensorMeasure5', 'SensorMeasure6', 'SensorMeasure10', 'SensorMeasure16', 'SensorMeasure18', 'SensorMeasure19']\n",
      "\n",
      "[0.03612309 0.03073992 0.03161087 0.05842176 0.03961355 0.02226721\n",
      " 0.02906953 0.58729662 0.06567317 0.0213243  0.02531437 0.04235231\n",
      " 0.01019329]\n"
     ]
    }
   ],
   "source": [
    "def call_EDA(file):\n",
    "  filename=file\n",
    "  res = pm.execute_notebook(\n",
    "    'EDA_and_Feature_Selection.ipynb'  ,\n",
    "    'CNN_LSTM_training_model.ipynb',\n",
    "    parameters = dict(filename=filename),\n",
    "    log_output=True,\n",
    "    stdout_file=sys.stdout,\n",
    "    stderr_file=sys.stderr,\n",
    "    )\n",
    "call_EDA('file1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENGINE_ID',\n",
       " 'OpSet1',\n",
       " 'OpSet2',\n",
       " 'CONDITION_ID',\n",
       " 'OpSet3',\n",
       " 'SensorMeasure1',\n",
       " 'SensorMeasure5',\n",
       " 'SensorMeasure6',\n",
       " 'SensorMeasure10',\n",
       " 'SensorMeasure16',\n",
       " 'SensorMeasure18',\n",
       " 'SensorMeasure19']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the list of columns to be dropped from training and test files from removed_columns.data\n",
    "import pickle\n",
    "\n",
    "with open('removed_columns.data', 'rb') as filehandle:\n",
    "    # Read the data as a binary data stream\n",
    "    removed_columns = pickle.load(filehandle)\n",
    "removed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete columns from removed_columns which are not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cycle_Time', 'SensorMeasure2', 'SensorMeasure3', 'SensorMeasure4',\n",
       "       'SensorMeasure7', 'SensorMeasure8', 'SensorMeasure9', 'SensorMeasure11',\n",
       "       'SensorMeasure12', 'SensorMeasure13', 'SensorMeasure14',\n",
       "       'SensorMeasure15', 'SensorMeasure17', 'SensorMeasure20',\n",
       "       'SensorMeasure21', 'RUL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv('file1.csv')\n",
    "train_data=train_data.drop(columns=removed_columns)\n",
    "training_columns=train_data.columns\n",
    "training_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WINDOWING\n",
    "WINDOW_SIZE=30\n",
    "BATCH_SIZE = 210   # No of samples processed before model is updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process target RUL \n",
    "def process_target_RUL(data_length, early_rul = None):\n",
    "    \"\"\" \n",
    "    Takes datalength and earlyrul as input and \n",
    "    creates target rul.\n",
    "    \"\"\"\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:   # \n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a numpy array with tuple containing feature and labels\n",
    "def process_dataset_with_target_RUL(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    \n",
    "    Depending on values of window_length and shift, this function generates batchs of data and targets \n",
    "    from input_data and target_data.\n",
    "    \n",
    "    Number of batches taken as a function of engine ID = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "    \n",
    "    **Input dimensions have not been checked and considered to be at par with the requirements**\n",
    "    \n",
    "    Arguments:\n",
    "        input_data: input data to function (2D array containing features and label)\n",
    "        target_data: input RUL values (1D array)\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of \n",
    "               29 data points between two consecutive batches.\n",
    "        \n",
    "    \"\"\"\n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3690ab1f2966f90930f31177e7e4bc8912eaec9459a68fe543e20f6f7018934"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
